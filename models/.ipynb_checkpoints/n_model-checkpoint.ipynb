{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72ca9841-adc6-4612-b82f-f2f94a32faa7",
   "metadata": {},
   "source": [
    "# preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6d127aa-802a-4ec0-9fc9-e2671c2dba1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#モデル\n",
    "import lightgbm as lgb\n",
    "\n",
    "#パラメータ探索\n",
    "import optuna\n",
    "\n",
    "#クロスバリデーション\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "#エヴァリュエーション\n",
    "from sklearn.metrics import precision_score, recall_score, mean_squared_error\n",
    "\n",
    "#可視化\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "#保存\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11351b30-8083-423f-a50c-46bfde76436b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#データを読み込む\n",
    "j_uma_race_df = pd.read_pickle('../datasets/traindata/j_uma_race.pkl')\n",
    "j_race_df = pd.read_pickle('../datasets/traindata/j_race.pkl')\n",
    "# j_payout_df = pd.read_pickle('../datasets/traindata/j_payout.pkl')\n",
    "\n",
    "n_uma_race_df = pd.read_pickle('../datasets/traindata/n_uma_race.pkl')\n",
    "n_race_df = pd.read_pickle('../datasets/traindata/n_race.pkl')\n",
    "n_payout_df = pd.read_pickle('../datasets/traindata/n_payout.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0bf1c2-3a54-4a11-9309-d830239210d8",
   "metadata": {},
   "source": [
    "# LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b27f25-1e3d-4bae-bc62-106ec78a6f4c",
   "metadata": {},
   "source": [
    "## グループクエリ用のカラムを作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c664d196-e826-4eba-9cf8-851ea81544cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 新しいグループを作成\n",
    "n_uma_race_df['group'] = n_uma_race_df['kaisai_nen'].astype(int).astype(str) +\"-\"+ n_uma_race_df['kaisai_tsukihi'].astype(int).astype(str) +\"-\"+  n_uma_race_df['keibajo_code'].astype(int).astype(str) +\"-\"+  n_uma_race_df['race_bango'].astype(int).astype(str)\n",
    "n_race_df['group'] = n_race_df['kaisai_nen'].astype(int).astype(str) +\"-\"+ n_race_df['kaisai_tsukihi'].astype(int).astype(str) +\"-\"+  n_race_df['keibajo_code'].astype(int).astype(str) +\"-\"+  n_race_df['race_bango'].astype(int).astype(str)\n",
    "n_payout_df['group'] = n_payout_df['kaisai_nen'].astype(int).astype(str) +\"-\"+ n_payout_df['kaisai_tsukihi'].astype(int).astype(str) +\"-\"+  n_payout_df['keibajo_code'].astype(int).astype(str) +\"-\"+  n_payout_df['race_bango'].astype(int).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8d688c7-8bbf-4e36-8b93-c6a421ae6ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_race_df = n_race_df.drop(['kaisai_nen', 'kaisai_tsukihi', 'keibajo_code', 'kaisai_kai', 'kaisai_nichime', 'race_bango'],axis=1)\n",
    "n_payout_df = n_payout_df.drop(['kaisai_nen', 'kaisai_tsukihi', 'keibajo_code', 'kaisai_kai', 'kaisai_nichime', 'race_bango', 'toroku_tosu', 'shusso_tosu'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "682b41b1-7f71-4963-b2d4-28fca1f51120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "205318"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df = pd.merge(n_uma_race_df, n_race_df, on='group', how='left')\n",
    "merged_df = pd.merge(merged_df, n_payout_df, on='group', how='left')\n",
    "merged_df['group'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15ff2e39-36ac-42c3-b039-0a870a1dc2f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kaisai_nen</th>\n",
       "      <th>kaisai_tsukihi</th>\n",
       "      <th>keibajo_code</th>\n",
       "      <th>kaisai_kai</th>\n",
       "      <th>kaisai_nichime</th>\n",
       "      <th>race_bango</th>\n",
       "      <th>wakuban</th>\n",
       "      <th>umaban</th>\n",
       "      <th>ketto_toroku_bango</th>\n",
       "      <th>bamei</th>\n",
       "      <th>umakigo_code</th>\n",
       "      <th>seibetsu_code</th>\n",
       "      <th>hinshu_code</th>\n",
       "      <th>moshoku_code</th>\n",
       "      <th>barei</th>\n",
       "      <th>tozai_shozoku_code</th>\n",
       "      <th>chokyoshi_code</th>\n",
       "      <th>banushi_code</th>\n",
       "      <th>banushimei</th>\n",
       "      <th>futan_juryo</th>\n",
       "      <th>blinker_shiyo_kubun</th>\n",
       "      <th>kishu_code</th>\n",
       "      <th>kishumei_ryakusho</th>\n",
       "      <th>kishu_minarai_code</th>\n",
       "      <th>bataiju</th>\n",
       "      <th>zogen_fugo</th>\n",
       "      <th>zogen_sa</th>\n",
       "      <th>ijo_kubun_code</th>\n",
       "      <th>nyusen_juni</th>\n",
       "      <th>kakutei_chakujun</th>\n",
       "      <th>dochaku_kubun</th>\n",
       "      <th>dochaku_tosu</th>\n",
       "      <th>soha_time</th>\n",
       "      <th>chakusa_code_1</th>\n",
       "      <th>chakusa_code_2</th>\n",
       "      <th>chakusa_code_3</th>\n",
       "      <th>corner_1</th>\n",
       "      <th>corner_2</th>\n",
       "      <th>corner_3</th>\n",
       "      <th>corner_4</th>\n",
       "      <th>tansho_odds</th>\n",
       "      <th>tansho_ninkijun</th>\n",
       "      <th>kakutoku_honshokin</th>\n",
       "      <th>kakutoku_fukashokin</th>\n",
       "      <th>kohan_4f</th>\n",
       "      <th>kohan_3f</th>\n",
       "      <th>aiteuma_joho_1</th>\n",
       "      <th>aiteuma_joho_2</th>\n",
       "      <th>aiteuma_joho_3</th>\n",
       "      <th>time_sa</th>\n",
       "      <th>record_koshin_kubun</th>\n",
       "      <th>kyakushitsu_hantei</th>\n",
       "      <th>group</th>\n",
       "      <th>yobi_code</th>\n",
       "      <th>jusho_kaiji</th>\n",
       "      <th>grade_code</th>\n",
       "      <th>kyoso_shubetsu_code</th>\n",
       "      <th>kyoso_kigo_code</th>\n",
       "      <th>juryo_shubetsu_code</th>\n",
       "      <th>kyoso_joken_code_2sai</th>\n",
       "      <th>kyoso_joken_code_3sai</th>\n",
       "      <th>kyoso_joken_code_4sai</th>\n",
       "      <th>kyoso_joken_code_5sai_ijo</th>\n",
       "      <th>kyoso_joken_code</th>\n",
       "      <th>kyori</th>\n",
       "      <th>track_code</th>\n",
       "      <th>course_kubun</th>\n",
       "      <th>honshokin</th>\n",
       "      <th>fukashokin</th>\n",
       "      <th>hasso_jikoku</th>\n",
       "      <th>toroku_tosu</th>\n",
       "      <th>shusso_tosu</th>\n",
       "      <th>nyusen_tosu</th>\n",
       "      <th>tenko_code</th>\n",
       "      <th>babajotai_code_shiba</th>\n",
       "      <th>babajotai_code_dirt</th>\n",
       "      <th>fuseiritsu_flag_sanrenpuku</th>\n",
       "      <th>tokubarai_flag_sanrenpuku</th>\n",
       "      <th>henkan_flag_sanrenpuku</th>\n",
       "      <th>haraimodoshi_sanrenpuku_1a</th>\n",
       "      <th>haraimodoshi_sanrenpuku_1b</th>\n",
       "      <th>haraimodoshi_sanrenpuku_1c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023</td>\n",
       "      <td>916</td>\n",
       "      <td>46</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2020106227</td>\n",
       "      <td>スターサファイア</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5319</td>\n",
       "      <td>875800</td>\n",
       "      <td>ＪＰＮ技研</td>\n",
       "      <td>560.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5300</td>\n",
       "      <td>葛山晃平</td>\n",
       "      <td>0</td>\n",
       "      <td>466.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1359</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>899</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>411</td>\n",
       "      <td>2020105068フェイマスグローリ</td>\n",
       "      <td>0000000000</td>\n",
       "      <td>0000000000</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-916-46-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1400</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>4.000000e+51</td>\n",
       "      <td>0</td>\n",
       "      <td>1140</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60809.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   kaisai_nen  kaisai_tsukihi keibajo_code  kaisai_kai  kaisai_nichime  \\\n",
       "0        2023             916           46          13               1   \n",
       "\n",
       "   race_bango  wakuban  umaban  ketto_toroku_bango               bamei  \\\n",
       "0           1        1       1          2020106227  スターサファイア　　　　　　　　　　   \n",
       "\n",
       "   umakigo_code  seibetsu_code  hinshu_code  moshoku_code  barei  \\\n",
       "0             0              1          1.0             3      3   \n",
       "\n",
       "   tozai_shozoku_code  chokyoshi_code  banushi_code  \\\n",
       "0                   3            5319        875800   \n",
       "\n",
       "                         banushimei  futan_juryo  blinker_shiyo_kubun  \\\n",
       "0  ＪＰＮ技研　　　　　　　　　　　　　　　　　　　　　　　　　　　        560.0                    0   \n",
       "\n",
       "   kishu_code kishumei_ryakusho  kishu_minarai_code  bataiju  zogen_fugo  \\\n",
       "0        5300              葛山晃平                   0    466.0           1   \n",
       "\n",
       "   zogen_sa  ijo_kubun_code  nyusen_juni  kakutei_chakujun  dochaku_kubun  \\\n",
       "0       0.0               0            8                 8              0   \n",
       "\n",
       "   dochaku_tosu  soha_time  chakusa_code_1  chakusa_code_2  chakusa_code_3  \\\n",
       "0             0       1359             4.0             NaN             NaN   \n",
       "\n",
       "   corner_1  corner_2  corner_3  corner_4  tansho_odds  tansho_ninkijun  \\\n",
       "0         9         9         9         9          899                8   \n",
       "\n",
       "   kakutoku_honshokin  kakutoku_fukashokin  kohan_4f  kohan_3f  \\\n",
       "0                   0                    0         0       411   \n",
       "\n",
       "                 aiteuma_joho_1                aiteuma_joho_2  \\\n",
       "0  2020105068フェイマスグローリ　　　　　　　　　  0000000000　　　　　　　　　　　　　　　　　　   \n",
       "\n",
       "                 aiteuma_joho_3  time_sa  record_koshin_kubun  \\\n",
       "0  0000000000　　　　　　　　　　　　　　　　　　       50                    0   \n",
       "\n",
       "   kyakushitsu_hantei          group  yobi_code  jusho_kaiji  grade_code  \\\n",
       "0                   0  2023-916-46-1          1            0           0   \n",
       "\n",
       "   kyoso_shubetsu_code  kyoso_kigo_code  juryo_shubetsu_code  \\\n",
       "0                   49                0                    4   \n",
       "\n",
       "   kyoso_joken_code_2sai  kyoso_joken_code_3sai  kyoso_joken_code_4sai  \\\n",
       "0                      0                      0                      0   \n",
       "\n",
       "   kyoso_joken_code_5sai_ijo  kyoso_joken_code  kyori  track_code  \\\n",
       "0                          0                 0   1400          24   \n",
       "\n",
       "   course_kubun     honshokin  fukashokin  hasso_jikoku  toroku_tosu  \\\n",
       "0             0  4.000000e+51           0          1140            9   \n",
       "\n",
       "   shusso_tosu  nyusen_tosu  tenko_code  babajotai_code_shiba  \\\n",
       "0            9            9           1                     0   \n",
       "\n",
       "   babajotai_code_dirt  fuseiritsu_flag_sanrenpuku  tokubarai_flag_sanrenpuku  \\\n",
       "0                  1.0                         0.0                        0.0   \n",
       "\n",
       "   henkan_flag_sanrenpuku  haraimodoshi_sanrenpuku_1a  \\\n",
       "0                     0.0                     60809.0   \n",
       "\n",
       "   haraimodoshi_sanrenpuku_1b  haraimodoshi_sanrenpuku_1c  \n",
       "0                       210.0                         1.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "merged_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49c5dcd5-97c7-4a71-9d8b-7c20af1494df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_df = merged_df[merged_df['track_code'] == 23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f43e44e6-e588-4837-9eab-2c1542f91680",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['hutan_wariai'] = merged_df['futan_juryo'] / merged_df['bataiju']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3207c5cf-150b-40c0-9b0f-278f94680871",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_sign_and_diff(row):\n",
    "    if row['zogen_fugo'] == 2:\n",
    "        return row['zogen_sa']\n",
    "    elif row['zogen_fugo'] == 0:\n",
    "        return -row['zogen_sa']\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "merged_df['zogen_ryou'] = merged_df.apply(combine_sign_and_diff, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9622447d-bc27-4919-8ec1-39e9a3d2bcfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged_df[merged_df['ijo_kubun_code'] == 0]\n",
    "# 1\t出走取消\t取消\tSCRATCHED\tS\n",
    "# 2\t発走除外\t発除\tEXCLUDED BY STARTERS\tES\n",
    "# 3\t競走除外\t競除\tEXCLUDED BY STEWARDS\tER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae2b6db6-3968-4a63-ab23-5b7a73ecc35d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kyori のデータ型: int32\n",
      "grade_code のデータ型: int32\n",
      "seibetsu_code のデータ型: int32\n",
      "moshoku_code のデータ型: int32\n",
      "barei のデータ型: int32\n",
      "chokyoshi_code のデータ型: int32\n",
      "banushi_code のデータ型: int32\n",
      "kishu_code のデータ型: int32\n",
      "kishu_minarai_code のデータ型: int32\n",
      "kyoso_shubetsu_code のデータ型: int32\n",
      "juryo_shubetsu_code のデータ型: int32\n",
      "shusso_tosu のデータ型: int32\n",
      "tenko_code のデータ型: int32\n",
      "babajotai_code_dirt のデータ型: int32\n",
      "hutan_wariai のデータ型: float64\n",
      "zogen_ryou のデータ型: int32\n",
      "track_code のデータ型: int32\n",
      "keibajo_code のデータ型: int32\n"
     ]
    }
   ],
   "source": [
    "columns_to_convert = [\n",
    "                    'kyori',\n",
    "                    'grade_code',\n",
    "                    'seibetsu_code',\n",
    "                    'moshoku_code',\n",
    "                    'barei',\n",
    "                    'chokyoshi_code',\n",
    "                    'banushi_code',\n",
    "                    'kishu_code',\n",
    "                    'kishu_minarai_code',\n",
    "                    'kyoso_shubetsu_code',\n",
    "                    'juryo_shubetsu_code',\n",
    "                    'shusso_tosu',\n",
    "                    'tenko_code',\n",
    "                    'babajotai_code_dirt',\n",
    "                    'hutan_wariai',\n",
    "                    'zogen_ryou',\n",
    "                    'track_code',\n",
    "                    'keibajo_code'\n",
    "                    ]\n",
    "\n",
    "for column in columns_to_convert:\n",
    "    merged_df[column].fillna(0, inplace=True)\n",
    "    try:\n",
    "        if merged_df[column].astype(float).apply(lambda x: x.is_integer()).all():\n",
    "            merged_df[column] = merged_df[column].astype(int)\n",
    "        else:\n",
    "            merged_df[column] = merged_df[column].astype(float)\n",
    "    except ValueError:\n",
    "        merged_df[column] = merged_df[column].astype(float)\n",
    "\n",
    "    print(f\"{column} のデータ型: {merged_df[column].dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404db4d0-689f-4582-a667-2be6d7fecbc2",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd3ec73-b197-423f-8369-098902e95083",
   "metadata": {},
   "source": [
    "### テスト用と学習用のデータに分け、モデルを作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9740ae80-b106-4159-a01e-765f87246544",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-09 13:16:00,780] A new study created in memory with name: no-name-95e800d7-3583-4a66-a39b-04d821f6ce24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024040 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1262\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168487, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 5.544397\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 3.14772\n",
      "[200]\tvalid_0's rmse: 3.14349\n",
      "[300]\tvalid_0's rmse: 3.13924\n",
      "[400]\tvalid_0's rmse: 3.13513\n",
      "[500]\tvalid_0's rmse: 3.13111\n",
      "[600]\tvalid_0's rmse: 3.1271\n",
      "[700]\tvalid_0's rmse: 3.12328\n",
      "[800]\tvalid_0's rmse: 3.11947\n",
      "[900]\tvalid_0's rmse: 3.11573\n",
      "[1000]\tvalid_0's rmse: 3.11201\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 3.11201\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020828 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1260\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168487, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 5.546099\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 3.15509\n",
      "[200]\tvalid_0's rmse: 3.15085\n",
      "[300]\tvalid_0's rmse: 3.14658\n",
      "[400]\tvalid_0's rmse: 3.14245\n",
      "[500]\tvalid_0's rmse: 3.13842\n",
      "[600]\tvalid_0's rmse: 3.13439\n",
      "[700]\tvalid_0's rmse: 3.13056\n",
      "[800]\tvalid_0's rmse: 3.12674\n",
      "[900]\tvalid_0's rmse: 3.12299\n",
      "[1000]\tvalid_0's rmse: 3.11927\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 3.11927\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025425 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1259\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168487, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 5.545975\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 3.15372\n",
      "[200]\tvalid_0's rmse: 3.14947\n",
      "[300]\tvalid_0's rmse: 3.1452\n",
      "[400]\tvalid_0's rmse: 3.14108\n",
      "[500]\tvalid_0's rmse: 3.13706\n",
      "[600]\tvalid_0's rmse: 3.13303\n",
      "[700]\tvalid_0's rmse: 3.12921\n",
      "[800]\tvalid_0's rmse: 3.1254\n",
      "[900]\tvalid_0's rmse: 3.12166\n",
      "[1000]\tvalid_0's rmse: 3.11794\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 3.11794\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025225 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1259\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168487, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 5.545916\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 3.15424\n",
      "[200]\tvalid_0's rmse: 3.15001\n",
      "[300]\tvalid_0's rmse: 3.14576\n",
      "[400]\tvalid_0's rmse: 3.14165\n",
      "[500]\tvalid_0's rmse: 3.13764\n",
      "[600]\tvalid_0's rmse: 3.13362\n",
      "[700]\tvalid_0's rmse: 3.12981\n",
      "[800]\tvalid_0's rmse: 3.12601\n",
      "[900]\tvalid_0's rmse: 3.12228\n",
      "[1000]\tvalid_0's rmse: 3.11857\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 3.11857\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.027475 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1261\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168488, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 5.543938\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 3.15173\n",
      "[200]\tvalid_0's rmse: 3.14752\n",
      "[300]\tvalid_0's rmse: 3.14328\n",
      "[400]\tvalid_0's rmse: 3.13919\n",
      "[500]\tvalid_0's rmse: 3.13519\n",
      "[600]\tvalid_0's rmse: 3.13118\n",
      "[700]\tvalid_0's rmse: 3.12739\n",
      "[800]\tvalid_0's rmse: 3.12359\n",
      "[900]\tvalid_0's rmse: 3.11988\n",
      "[1000]\tvalid_0's rmse: 3.11617\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 3.11617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-09 13:20:00,276] Trial 0 finished with value: 3.116791384214117 and parameters: {'num_leaves': 63, 'learning_rate': 0.00011700588142666476, 'feature_fraction': 0.6223952906704244}. Best is trial 0 with value: 3.116791384214117.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024495 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1262\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168487, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 5.544397\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 3.13132\n",
      "[200]\tvalid_0's rmse: 3.11307\n",
      "[300]\tvalid_0's rmse: 3.09577\n",
      "[400]\tvalid_0's rmse: 3.08003\n",
      "[500]\tvalid_0's rmse: 3.06546\n",
      "[600]\tvalid_0's rmse: 3.05232\n",
      "[700]\tvalid_0's rmse: 3.04044\n",
      "[800]\tvalid_0's rmse: 3.02975\n",
      "[900]\tvalid_0's rmse: 3.01996\n",
      "[1000]\tvalid_0's rmse: 3.01071\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 3.01071\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024380 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1260\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168487, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 5.546099\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 3.13859\n",
      "[200]\tvalid_0's rmse: 3.12026\n",
      "[300]\tvalid_0's rmse: 3.1029\n",
      "[400]\tvalid_0's rmse: 3.0871\n",
      "[500]\tvalid_0's rmse: 3.0725\n",
      "[600]\tvalid_0's rmse: 3.05934\n",
      "[700]\tvalid_0's rmse: 3.04746\n",
      "[800]\tvalid_0's rmse: 3.03676\n",
      "[900]\tvalid_0's rmse: 3.02697\n",
      "[1000]\tvalid_0's rmse: 3.01776\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 3.01776\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025097 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1259\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168487, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 5.545975\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 3.13726\n",
      "[200]\tvalid_0's rmse: 3.11894\n",
      "[300]\tvalid_0's rmse: 3.10162\n",
      "[400]\tvalid_0's rmse: 3.08588\n",
      "[500]\tvalid_0's rmse: 3.07131\n",
      "[600]\tvalid_0's rmse: 3.05822\n",
      "[700]\tvalid_0's rmse: 3.04638\n",
      "[800]\tvalid_0's rmse: 3.03571\n",
      "[900]\tvalid_0's rmse: 3.02596\n",
      "[1000]\tvalid_0's rmse: 3.01679\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 3.01679\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024371 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1259\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168487, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 5.545916\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 3.13785\n",
      "[200]\tvalid_0's rmse: 3.11962\n",
      "[300]\tvalid_0's rmse: 3.10238\n",
      "[400]\tvalid_0's rmse: 3.08673\n",
      "[500]\tvalid_0's rmse: 3.07223\n",
      "[600]\tvalid_0's rmse: 3.05918\n",
      "[700]\tvalid_0's rmse: 3.04739\n",
      "[800]\tvalid_0's rmse: 3.03679\n",
      "[900]\tvalid_0's rmse: 3.02707\n",
      "[1000]\tvalid_0's rmse: 3.01794\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 3.01794\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.030161 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1261\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168488, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 5.543938\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 3.13541\n",
      "[200]\tvalid_0's rmse: 3.11723\n",
      "[300]\tvalid_0's rmse: 3.10002\n",
      "[400]\tvalid_0's rmse: 3.08438\n",
      "[500]\tvalid_0's rmse: 3.06988\n",
      "[600]\tvalid_0's rmse: 3.05683\n",
      "[700]\tvalid_0's rmse: 3.04502\n",
      "[800]\tvalid_0's rmse: 3.03438\n",
      "[900]\tvalid_0's rmse: 3.02463\n",
      "[1000]\tvalid_0's rmse: 3.01544\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 3.01544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-09 13:22:36,931] Trial 1 finished with value: 3.015728650602524 and parameters: {'num_leaves': 13, 'learning_rate': 0.0005990267804761253, 'feature_fraction': 0.7842135319769059}. Best is trial 1 with value: 3.015728650602524.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.032635 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1262\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168487, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 5.544397\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 3.14478\n",
      "[200]\tvalid_0's rmse: 3.13774\n",
      "[300]\tvalid_0's rmse: 3.1307\n",
      "[400]\tvalid_0's rmse: 3.12387\n",
      "[500]\tvalid_0's rmse: 3.11716\n",
      "[600]\tvalid_0's rmse: 3.11069\n",
      "[700]\tvalid_0's rmse: 3.10446\n",
      "[800]\tvalid_0's rmse: 3.09849\n",
      "[900]\tvalid_0's rmse: 3.09268\n",
      "[1000]\tvalid_0's rmse: 3.0869\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 3.0869\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.030797 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1260\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168487, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 5.546099\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 3.15215\n",
      "[200]\tvalid_0's rmse: 3.14509\n",
      "[300]\tvalid_0's rmse: 3.13803\n",
      "[400]\tvalid_0's rmse: 3.1312\n",
      "[500]\tvalid_0's rmse: 3.12448\n",
      "[600]\tvalid_0's rmse: 3.11801\n",
      "[700]\tvalid_0's rmse: 3.11178\n",
      "[800]\tvalid_0's rmse: 3.10581\n",
      "[900]\tvalid_0's rmse: 3.09999\n",
      "[1000]\tvalid_0's rmse: 3.0942\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 3.0942\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.041552 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1259\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168487, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 5.545975\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 3.15076\n",
      "[200]\tvalid_0's rmse: 3.14372\n",
      "[300]\tvalid_0's rmse: 3.13665\n",
      "[400]\tvalid_0's rmse: 3.12981\n",
      "[500]\tvalid_0's rmse: 3.12308\n",
      "[600]\tvalid_0's rmse: 3.11661\n",
      "[700]\tvalid_0's rmse: 3.11037\n",
      "[800]\tvalid_0's rmse: 3.10439\n",
      "[900]\tvalid_0's rmse: 3.09857\n",
      "[1000]\tvalid_0's rmse: 3.09279\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 3.09279\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.026310 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1259\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168487, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 5.545916\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 3.1513\n",
      "[200]\tvalid_0's rmse: 3.14426\n",
      "[300]\tvalid_0's rmse: 3.13722\n",
      "[400]\tvalid_0's rmse: 3.1304\n",
      "[500]\tvalid_0's rmse: 3.12371\n",
      "[600]\tvalid_0's rmse: 3.11725\n",
      "[700]\tvalid_0's rmse: 3.11104\n",
      "[800]\tvalid_0's rmse: 3.10509\n",
      "[900]\tvalid_0's rmse: 3.0993\n",
      "[1000]\tvalid_0's rmse: 3.09354\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 3.09354\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.034195 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1261\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168488, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 5.543938\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 3.14881\n",
      "[200]\tvalid_0's rmse: 3.1418\n",
      "[300]\tvalid_0's rmse: 3.13477\n",
      "[400]\tvalid_0's rmse: 3.12797\n",
      "[500]\tvalid_0's rmse: 3.12129\n",
      "[600]\tvalid_0's rmse: 3.11485\n",
      "[700]\tvalid_0's rmse: 3.10866\n",
      "[800]\tvalid_0's rmse: 3.10272\n",
      "[900]\tvalid_0's rmse: 3.09693\n",
      "[1000]\tvalid_0's rmse: 3.09118\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 3.09118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-09 13:26:18,624] Trial 2 finished with value: 3.0917229722898023 and parameters: {'num_leaves': 48, 'learning_rate': 0.00018541112600391722, 'feature_fraction': 0.793573796177522}. Best is trial 1 with value: 3.015728650602524.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023854 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1262\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168487, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 5.544397\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 3.08786\n",
      "[200]\tvalid_0's rmse: 3.03864\n",
      "[300]\tvalid_0's rmse: 2.99891\n",
      "[400]\tvalid_0's rmse: 2.96762\n",
      "[500]\tvalid_0's rmse: 2.94246\n",
      "[600]\tvalid_0's rmse: 2.92241\n",
      "[700]\tvalid_0's rmse: 2.90627\n",
      "[800]\tvalid_0's rmse: 2.89305\n",
      "[900]\tvalid_0's rmse: 2.8822\n",
      "[1000]\tvalid_0's rmse: 2.87293\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 2.87293\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023925 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1260\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168487, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 5.546099\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 3.09508\n",
      "[200]\tvalid_0's rmse: 3.04573\n",
      "[300]\tvalid_0's rmse: 3.00589\n",
      "[400]\tvalid_0's rmse: 2.97457\n",
      "[500]\tvalid_0's rmse: 2.94947\n",
      "[600]\tvalid_0's rmse: 2.92945\n",
      "[700]\tvalid_0's rmse: 2.91326\n",
      "[800]\tvalid_0's rmse: 2.90011\n",
      "[900]\tvalid_0's rmse: 2.88922\n",
      "[1000]\tvalid_0's rmse: 2.8802\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 2.8802\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.049639 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1259\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168487, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 5.545975\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 3.09375\n",
      "[200]\tvalid_0's rmse: 3.04446\n",
      "[300]\tvalid_0's rmse: 3.0047\n",
      "[400]\tvalid_0's rmse: 2.97342\n",
      "[500]\tvalid_0's rmse: 2.94828\n",
      "[600]\tvalid_0's rmse: 2.92836\n",
      "[700]\tvalid_0's rmse: 2.91223\n",
      "[800]\tvalid_0's rmse: 2.89911\n",
      "[900]\tvalid_0's rmse: 2.88811\n",
      "[1000]\tvalid_0's rmse: 2.87895\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 2.87895\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.028596 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1259\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168487, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 5.545916\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 3.09445\n",
      "[200]\tvalid_0's rmse: 3.04527\n",
      "[300]\tvalid_0's rmse: 3.00565\n",
      "[400]\tvalid_0's rmse: 2.97448\n",
      "[500]\tvalid_0's rmse: 2.94941\n",
      "[600]\tvalid_0's rmse: 2.92951\n",
      "[700]\tvalid_0's rmse: 2.91351\n",
      "[800]\tvalid_0's rmse: 2.90043\n",
      "[900]\tvalid_0's rmse: 2.88967\n",
      "[1000]\tvalid_0's rmse: 2.88043\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 2.88043\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.035018 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1261\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168488, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 5.543938\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 3.09225\n",
      "[200]\tvalid_0's rmse: 3.0432\n",
      "[300]\tvalid_0's rmse: 3.00362\n",
      "[400]\tvalid_0's rmse: 2.97249\n",
      "[500]\tvalid_0's rmse: 2.94739\n",
      "[600]\tvalid_0's rmse: 2.92744\n",
      "[700]\tvalid_0's rmse: 2.91134\n",
      "[800]\tvalid_0's rmse: 2.89814\n",
      "[900]\tvalid_0's rmse: 2.88722\n",
      "[1000]\tvalid_0's rmse: 2.87808\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 2.87808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-09 13:33:19,055] Trial 3 finished with value: 2.8781185053187173 and parameters: {'num_leaves': 225, 'learning_rate': 0.0015822293741936742, 'feature_fraction': 0.7614122671499817}. Best is trial 3 with value: 2.8781185053187173.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.031051 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1262\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168487, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 5.544397\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 3.14111\n",
      "[200]\tvalid_0's rmse: 3.13176\n",
      "[300]\tvalid_0's rmse: 3.12176\n",
      "[400]\tvalid_0's rmse: 3.11219\n",
      "[500]\tvalid_0's rmse: 3.10329\n",
      "[600]\tvalid_0's rmse: 3.09436\n",
      "[700]\tvalid_0's rmse: 3.08633\n",
      "[800]\tvalid_0's rmse: 3.07834\n",
      "[900]\tvalid_0's rmse: 3.07096\n",
      "[1000]\tvalid_0's rmse: 3.06376\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 3.06376\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024641 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1260\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168487, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 5.546099\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 3.14844\n",
      "[200]\tvalid_0's rmse: 3.13904\n",
      "[300]\tvalid_0's rmse: 3.12898\n",
      "[400]\tvalid_0's rmse: 3.11936\n",
      "[500]\tvalid_0's rmse: 3.11043\n",
      "[600]\tvalid_0's rmse: 3.10146\n",
      "[700]\tvalid_0's rmse: 3.09339\n",
      "[800]\tvalid_0's rmse: 3.08536\n",
      "[900]\tvalid_0's rmse: 3.07794\n",
      "[1000]\tvalid_0's rmse: 3.07072\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 3.07072\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.029203 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1259\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168487, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 5.545975\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 3.14707\n",
      "[200]\tvalid_0's rmse: 3.13767\n",
      "[300]\tvalid_0's rmse: 3.12765\n",
      "[400]\tvalid_0's rmse: 3.11805\n",
      "[500]\tvalid_0's rmse: 3.10914\n",
      "[600]\tvalid_0's rmse: 3.10018\n",
      "[700]\tvalid_0's rmse: 3.09214\n",
      "[800]\tvalid_0's rmse: 3.08414\n",
      "[900]\tvalid_0's rmse: 3.07674\n",
      "[1000]\tvalid_0's rmse: 3.06955\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 3.06955\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024040 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1259\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168487, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 5.545916\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 3.1476\n",
      "[200]\tvalid_0's rmse: 3.13824\n",
      "[300]\tvalid_0's rmse: 3.12825\n",
      "[400]\tvalid_0's rmse: 3.11869\n",
      "[500]\tvalid_0's rmse: 3.10981\n",
      "[600]\tvalid_0's rmse: 3.10088\n",
      "[700]\tvalid_0's rmse: 3.09285\n",
      "[800]\tvalid_0's rmse: 3.08487\n",
      "[900]\tvalid_0's rmse: 3.07749\n",
      "[1000]\tvalid_0's rmse: 3.07031\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 3.07031\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020053 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1261\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168488, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 5.543938\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 3.14514\n",
      "[200]\tvalid_0's rmse: 3.1358\n",
      "[300]\tvalid_0's rmse: 3.12584\n",
      "[400]\tvalid_0's rmse: 3.11629\n",
      "[500]\tvalid_0's rmse: 3.10744\n",
      "[600]\tvalid_0's rmse: 3.09854\n",
      "[700]\tvalid_0's rmse: 3.09054\n",
      "[800]\tvalid_0's rmse: 3.08257\n",
      "[900]\tvalid_0's rmse: 3.07522\n",
      "[1000]\tvalid_0's rmse: 3.06807\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 3.06807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-09 13:38:09,042] Trial 4 finished with value: 3.068482036006615 and parameters: {'num_leaves': 125, 'learning_rate': 0.0003153799310015892, 'feature_fraction': 0.43340828472230225}. Best is trial 3 with value: 2.8781185053187173.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.044396 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1262\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168487, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 5.544397\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 2.96841\n",
      "[200]\tvalid_0's rmse: 2.90086\n",
      "[300]\tvalid_0's rmse: 2.86953\n",
      "[400]\tvalid_0's rmse: 2.85099\n",
      "[500]\tvalid_0's rmse: 2.8395\n",
      "[600]\tvalid_0's rmse: 2.83066\n",
      "[700]\tvalid_0's rmse: 2.82278\n",
      "[800]\tvalid_0's rmse: 2.81685\n",
      "[900]\tvalid_0's rmse: 2.81149\n",
      "[1000]\tvalid_0's rmse: 2.80676\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 2.80676\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022526 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1260\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168487, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 5.546099\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 2.97552\n",
      "[200]\tvalid_0's rmse: 2.90823\n",
      "[300]\tvalid_0's rmse: 2.87746\n",
      "[400]\tvalid_0's rmse: 2.85917\n",
      "[500]\tvalid_0's rmse: 2.84683\n",
      "[600]\tvalid_0's rmse: 2.83793\n",
      "[700]\tvalid_0's rmse: 2.83061\n",
      "[800]\tvalid_0's rmse: 2.82472\n",
      "[900]\tvalid_0's rmse: 2.81895\n",
      "[1000]\tvalid_0's rmse: 2.8139\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 2.8139\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023818 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1259\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168487, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 5.545975\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 2.97424\n",
      "[200]\tvalid_0's rmse: 2.90738\n",
      "[300]\tvalid_0's rmse: 2.87618\n",
      "[400]\tvalid_0's rmse: 2.8577\n",
      "[500]\tvalid_0's rmse: 2.84569\n",
      "[600]\tvalid_0's rmse: 2.83685\n",
      "[700]\tvalid_0's rmse: 2.82926\n",
      "[800]\tvalid_0's rmse: 2.82303\n",
      "[900]\tvalid_0's rmse: 2.81786\n",
      "[1000]\tvalid_0's rmse: 2.8127\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 2.8127\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.027539 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1259\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168487, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 5.545916\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 2.97536\n",
      "[200]\tvalid_0's rmse: 2.90866\n",
      "[300]\tvalid_0's rmse: 2.87772\n",
      "[400]\tvalid_0's rmse: 2.8597\n",
      "[500]\tvalid_0's rmse: 2.84781\n",
      "[600]\tvalid_0's rmse: 2.83885\n",
      "[700]\tvalid_0's rmse: 2.83129\n",
      "[800]\tvalid_0's rmse: 2.82518\n",
      "[900]\tvalid_0's rmse: 2.81959\n",
      "[1000]\tvalid_0's rmse: 2.81451\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 2.81451\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024245 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1261\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168488, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 5.543938\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 2.97313\n",
      "[200]\tvalid_0's rmse: 2.90633\n",
      "[300]\tvalid_0's rmse: 2.87502\n",
      "[400]\tvalid_0's rmse: 2.85679\n",
      "[500]\tvalid_0's rmse: 2.84495\n",
      "[600]\tvalid_0's rmse: 2.83588\n",
      "[700]\tvalid_0's rmse: 2.82834\n",
      "[800]\tvalid_0's rmse: 2.822\n",
      "[900]\tvalid_0's rmse: 2.81678\n",
      "[1000]\tvalid_0's rmse: 2.81165\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 2.81165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-09 13:44:07,276] Trial 5 finished with value: 2.811904608750376 and parameters: {'num_leaves': 127, 'learning_rate': 0.006339377779644475, 'feature_fraction': 0.9014309306425972}. Best is trial 5 with value: 2.811904608750376.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.032365 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1262\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168487, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 5.544397\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 2.83472\n",
      "[200]\tvalid_0's rmse: 2.80393\n",
      "[300]\tvalid_0's rmse: 2.79041\n",
      "[400]\tvalid_0's rmse: 2.78318\n",
      "[500]\tvalid_0's rmse: 2.77727\n",
      "[600]\tvalid_0's rmse: 2.7721\n",
      "[700]\tvalid_0's rmse: 2.76818\n",
      "[800]\tvalid_0's rmse: 2.7644\n",
      "[900]\tvalid_0's rmse: 2.76107\n",
      "[1000]\tvalid_0's rmse: 2.75812\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 2.75812\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025196 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1260\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168487, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 5.546099\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 2.8419\n",
      "[200]\tvalid_0's rmse: 2.81039\n",
      "[300]\tvalid_0's rmse: 2.7969\n",
      "[400]\tvalid_0's rmse: 2.78939\n",
      "[500]\tvalid_0's rmse: 2.78317\n",
      "[600]\tvalid_0's rmse: 2.77845\n",
      "[700]\tvalid_0's rmse: 2.77468\n",
      "[800]\tvalid_0's rmse: 2.77068\n",
      "[900]\tvalid_0's rmse: 2.76705\n",
      "[1000]\tvalid_0's rmse: 2.76392\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 2.76392\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024139 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1259\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168487, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 5.545975\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 2.84197\n",
      "[200]\tvalid_0's rmse: 2.80986\n",
      "[300]\tvalid_0's rmse: 2.79603\n",
      "[400]\tvalid_0's rmse: 2.78819\n",
      "[500]\tvalid_0's rmse: 2.78211\n",
      "[600]\tvalid_0's rmse: 2.77697\n",
      "[700]\tvalid_0's rmse: 2.77268\n",
      "[800]\tvalid_0's rmse: 2.76927\n",
      "[900]\tvalid_0's rmse: 2.76626\n",
      "[1000]\tvalid_0's rmse: 2.7635\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 2.7635\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.026581 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1259\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168487, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 5.545916\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 2.84218\n",
      "[200]\tvalid_0's rmse: 2.81072\n",
      "[300]\tvalid_0's rmse: 2.79752\n",
      "[400]\tvalid_0's rmse: 2.78952\n",
      "[500]\tvalid_0's rmse: 2.78333\n",
      "[600]\tvalid_0's rmse: 2.77846\n",
      "[700]\tvalid_0's rmse: 2.77384\n",
      "[800]\tvalid_0's rmse: 2.77017\n",
      "[900]\tvalid_0's rmse: 2.76679\n",
      "[1000]\tvalid_0's rmse: 2.764\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[999]\tvalid_0's rmse: 2.764\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.032327 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1261\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168488, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 5.543938\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 2.84001\n",
      "[200]\tvalid_0's rmse: 2.80813\n",
      "[300]\tvalid_0's rmse: 2.79472\n",
      "[400]\tvalid_0's rmse: 2.78719\n",
      "[500]\tvalid_0's rmse: 2.78056\n",
      "[600]\tvalid_0's rmse: 2.77545\n",
      "[700]\tvalid_0's rmse: 2.77142\n",
      "[800]\tvalid_0's rmse: 2.76766\n",
      "[900]\tvalid_0's rmse: 2.76469\n",
      "[1000]\tvalid_0's rmse: 2.76206\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 2.76206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-09 13:47:32,749] Trial 6 finished with value: 2.762319850777736 and parameters: {'num_leaves': 123, 'learning_rate': 0.03400344206608704, 'feature_fraction': 0.5850891923505196}. Best is trial 6 with value: 2.762319850777736.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.030228 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1262\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168487, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 5.544397\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 3.14423\n",
      "[200]\tvalid_0's rmse: 3.13651\n",
      "[300]\tvalid_0's rmse: 3.12906\n",
      "[400]\tvalid_0's rmse: 3.12182\n",
      "[500]\tvalid_0's rmse: 3.11474\n",
      "[600]\tvalid_0's rmse: 3.10792\n",
      "[700]\tvalid_0's rmse: 3.10132\n",
      "[800]\tvalid_0's rmse: 3.09492\n",
      "[900]\tvalid_0's rmse: 3.0887\n",
      "[1000]\tvalid_0's rmse: 3.08265\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 3.08265\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022600 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1260\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168487, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 5.546099\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 3.15161\n",
      "[200]\tvalid_0's rmse: 3.14387\n",
      "[300]\tvalid_0's rmse: 3.1364\n",
      "[400]\tvalid_0's rmse: 3.12915\n",
      "[500]\tvalid_0's rmse: 3.12205\n",
      "[600]\tvalid_0's rmse: 3.11522\n",
      "[700]\tvalid_0's rmse: 3.10861\n",
      "[800]\tvalid_0's rmse: 3.10219\n",
      "[900]\tvalid_0's rmse: 3.09596\n",
      "[1000]\tvalid_0's rmse: 3.08989\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 3.08989\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025367 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1259\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168487, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 5.545975\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 3.1502\n",
      "[200]\tvalid_0's rmse: 3.14244\n",
      "[300]\tvalid_0's rmse: 3.13495\n",
      "[400]\tvalid_0's rmse: 3.12768\n",
      "[500]\tvalid_0's rmse: 3.12055\n",
      "[600]\tvalid_0's rmse: 3.11371\n",
      "[700]\tvalid_0's rmse: 3.1071\n",
      "[800]\tvalid_0's rmse: 3.10068\n",
      "[900]\tvalid_0's rmse: 3.09445\n",
      "[1000]\tvalid_0's rmse: 3.08838\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 3.08838\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021211 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1259\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168487, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 5.545916\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 3.15075\n",
      "[200]\tvalid_0's rmse: 3.14302\n",
      "[300]\tvalid_0's rmse: 3.13556\n",
      "[400]\tvalid_0's rmse: 3.12831\n",
      "[500]\tvalid_0's rmse: 3.12121\n",
      "[600]\tvalid_0's rmse: 3.11439\n",
      "[700]\tvalid_0's rmse: 3.1078\n",
      "[800]\tvalid_0's rmse: 3.1014\n",
      "[900]\tvalid_0's rmse: 3.09519\n",
      "[1000]\tvalid_0's rmse: 3.08915\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 3.08915\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.028581 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1261\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168488, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 5.543938\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 3.14826\n",
      "[200]\tvalid_0's rmse: 3.14056\n",
      "[300]\tvalid_0's rmse: 3.13313\n",
      "[400]\tvalid_0's rmse: 3.12591\n",
      "[500]\tvalid_0's rmse: 3.11884\n",
      "[600]\tvalid_0's rmse: 3.11204\n",
      "[700]\tvalid_0's rmse: 3.10547\n",
      "[800]\tvalid_0's rmse: 3.09909\n",
      "[900]\tvalid_0's rmse: 3.0929\n",
      "[1000]\tvalid_0's rmse: 3.08688\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 3.08688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-09 13:52:40,244] Trial 7 finished with value: 3.087391236991596 and parameters: {'num_leaves': 111, 'learning_rate': 0.0001723322411388162, 'feature_fraction': 0.9280220458537989}. Best is trial 6 with value: 2.762319850777736.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.027566 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1262\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168487, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 5.544397\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 3.14359\n",
      "[200]\tvalid_0's rmse: 3.13599\n",
      "[300]\tvalid_0's rmse: 3.12792\n",
      "[400]\tvalid_0's rmse: 3.12037\n",
      "[500]\tvalid_0's rmse: 3.11321\n",
      "[600]\tvalid_0's rmse: 3.10595\n",
      "[700]\tvalid_0's rmse: 3.09924\n",
      "[800]\tvalid_0's rmse: 3.09252\n",
      "[900]\tvalid_0's rmse: 3.08625\n",
      "[1000]\tvalid_0's rmse: 3.07988\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 3.07988\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.028752 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1260\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168487, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 5.546099\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 3.15094\n",
      "[200]\tvalid_0's rmse: 3.14331\n",
      "[300]\tvalid_0's rmse: 3.13519\n",
      "[400]\tvalid_0's rmse: 3.1276\n",
      "[500]\tvalid_0's rmse: 3.12041\n",
      "[600]\tvalid_0's rmse: 3.11312\n",
      "[700]\tvalid_0's rmse: 3.10639\n",
      "[800]\tvalid_0's rmse: 3.09964\n",
      "[900]\tvalid_0's rmse: 3.09334\n",
      "[1000]\tvalid_0's rmse: 3.08695\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 3.08695\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022930 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1259\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168487, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 5.545975\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 3.14957\n",
      "[200]\tvalid_0's rmse: 3.14194\n",
      "[300]\tvalid_0's rmse: 3.13384\n",
      "[400]\tvalid_0's rmse: 3.12627\n",
      "[500]\tvalid_0's rmse: 3.1191\n",
      "[600]\tvalid_0's rmse: 3.11183\n",
      "[700]\tvalid_0's rmse: 3.1051\n",
      "[800]\tvalid_0's rmse: 3.09837\n",
      "[900]\tvalid_0's rmse: 3.0921\n",
      "[1000]\tvalid_0's rmse: 3.08572\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 3.08572\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024844 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1259\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168487, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 5.545916\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 3.1501\n",
      "[200]\tvalid_0's rmse: 3.14249\n",
      "[300]\tvalid_0's rmse: 3.13442\n",
      "[400]\tvalid_0's rmse: 3.12687\n",
      "[500]\tvalid_0's rmse: 3.11972\n",
      "[600]\tvalid_0's rmse: 3.11247\n",
      "[700]\tvalid_0's rmse: 3.10576\n",
      "[800]\tvalid_0's rmse: 3.09906\n",
      "[900]\tvalid_0's rmse: 3.0928\n",
      "[1000]\tvalid_0's rmse: 3.08643\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 3.08643\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022713 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1261\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168488, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 5.543938\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 3.14762\n",
      "[200]\tvalid_0's rmse: 3.14005\n",
      "[300]\tvalid_0's rmse: 3.132\n",
      "[400]\tvalid_0's rmse: 3.12448\n",
      "[500]\tvalid_0's rmse: 3.11735\n",
      "[600]\tvalid_0's rmse: 3.11012\n",
      "[700]\tvalid_0's rmse: 3.10343\n",
      "[800]\tvalid_0's rmse: 3.09674\n",
      "[900]\tvalid_0's rmse: 3.09049\n",
      "[1000]\tvalid_0's rmse: 3.08415\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 3.08415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-09 13:58:00,495] Trial 8 finished with value: 3.0846256744998497 and parameters: {'num_leaves': 135, 'learning_rate': 0.00023073729775381733, 'feature_fraction': 0.4937332241225361}. Best is trial 6 with value: 2.762319850777736.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022716 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1262\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168487, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 5.544397\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 2.82801\n",
      "[200]\tvalid_0's rmse: 2.79486\n",
      "[300]\tvalid_0's rmse: 2.77989\n",
      "[400]\tvalid_0's rmse: 2.771\n",
      "[500]\tvalid_0's rmse: 2.76431\n",
      "[600]\tvalid_0's rmse: 2.75892\n",
      "[700]\tvalid_0's rmse: 2.75436\n",
      "[800]\tvalid_0's rmse: 2.75056\n",
      "[900]\tvalid_0's rmse: 2.74662\n",
      "[1000]\tvalid_0's rmse: 2.74344\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 2.74344\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025517 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1260\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168487, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 5.546099\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 2.83487\n",
      "[200]\tvalid_0's rmse: 2.8008\n",
      "[300]\tvalid_0's rmse: 2.78621\n",
      "[400]\tvalid_0's rmse: 2.77768\n",
      "[500]\tvalid_0's rmse: 2.77055\n",
      "[600]\tvalid_0's rmse: 2.76554\n",
      "[700]\tvalid_0's rmse: 2.76052\n",
      "[800]\tvalid_0's rmse: 2.75648\n",
      "[900]\tvalid_0's rmse: 2.75272\n",
      "[1000]\tvalid_0's rmse: 2.74957\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 2.74957\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022290 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1259\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168487, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 5.545975\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 2.83413\n",
      "[200]\tvalid_0's rmse: 2.79949\n",
      "[300]\tvalid_0's rmse: 2.78407\n",
      "[400]\tvalid_0's rmse: 2.77594\n",
      "[500]\tvalid_0's rmse: 2.76939\n",
      "[600]\tvalid_0's rmse: 2.76391\n",
      "[700]\tvalid_0's rmse: 2.7596\n",
      "[800]\tvalid_0's rmse: 2.75551\n",
      "[900]\tvalid_0's rmse: 2.75247\n",
      "[1000]\tvalid_0's rmse: 2.74946\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 2.74946\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.027438 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1259\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168487, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 5.545916\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 2.83608\n",
      "[200]\tvalid_0's rmse: 2.80135\n",
      "[300]\tvalid_0's rmse: 2.78645\n",
      "[400]\tvalid_0's rmse: 2.77732\n",
      "[500]\tvalid_0's rmse: 2.77054\n",
      "[600]\tvalid_0's rmse: 2.765\n",
      "[700]\tvalid_0's rmse: 2.76027\n",
      "[800]\tvalid_0's rmse: 2.75661\n",
      "[900]\tvalid_0's rmse: 2.75289\n",
      "[1000]\tvalid_0's rmse: 2.74966\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 2.74966\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.029436 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1261\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168488, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 5.543938\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 2.83316\n",
      "[200]\tvalid_0's rmse: 2.79796\n",
      "[300]\tvalid_0's rmse: 2.78361\n",
      "[400]\tvalid_0's rmse: 2.77477\n",
      "[500]\tvalid_0's rmse: 2.76762\n",
      "[600]\tvalid_0's rmse: 2.76256\n",
      "[700]\tvalid_0's rmse: 2.75798\n",
      "[800]\tvalid_0's rmse: 2.75348\n",
      "[900]\tvalid_0's rmse: 2.75005\n",
      "[1000]\tvalid_0's rmse: 2.74687\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 2.74687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-09 14:01:47,979] Trial 9 finished with value: 2.7478013040106246 and parameters: {'num_leaves': 221, 'learning_rate': 0.03182715962026253, 'feature_fraction': 0.9102484532809859}. Best is trial 9 with value: 2.7478013040106246.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023903 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1262\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168487, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 5.544397\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[100]\tvalid_0's rmse: 2.82801\n",
      "[200]\tvalid_0's rmse: 2.79486\n",
      "[300]\tvalid_0's rmse: 2.77989\n",
      "[400]\tvalid_0's rmse: 2.771\n",
      "[500]\tvalid_0's rmse: 2.76431\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's rmse: 2.76431\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.049104 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1260\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168487, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 5.546099\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[100]\tvalid_0's rmse: 2.83487\n",
      "[200]\tvalid_0's rmse: 2.8008\n",
      "[300]\tvalid_0's rmse: 2.78621\n",
      "[400]\tvalid_0's rmse: 2.77768\n",
      "[500]\tvalid_0's rmse: 2.77055\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[499]\tvalid_0's rmse: 2.77055\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023570 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1259\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168487, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 5.545975\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[100]\tvalid_0's rmse: 2.83413\n",
      "[200]\tvalid_0's rmse: 2.79949\n",
      "[300]\tvalid_0's rmse: 2.78407\n",
      "[400]\tvalid_0's rmse: 2.77594\n",
      "[500]\tvalid_0's rmse: 2.76939\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's rmse: 2.76939\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023586 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1259\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168487, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 5.545916\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[100]\tvalid_0's rmse: 2.83608\n",
      "[200]\tvalid_0's rmse: 2.80135\n",
      "[300]\tvalid_0's rmse: 2.78645\n",
      "[400]\tvalid_0's rmse: 2.77732\n",
      "[500]\tvalid_0's rmse: 2.77054\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's rmse: 2.77054\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.027163 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1261\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168488, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 5.543938\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[100]\tvalid_0's rmse: 2.83316\n",
      "[200]\tvalid_0's rmse: 2.79796\n",
      "[300]\tvalid_0's rmse: 2.78361\n",
      "[400]\tvalid_0's rmse: 2.77477\n",
      "[500]\tvalid_0's rmse: 2.76762\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's rmse: 2.76762\n"
     ]
    }
   ],
   "source": [
    "# 2010年から2019年のデータを学習データとして取得\n",
    "train_data = merged_df[merged_df['kaisai_nen'].isin([2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019])]\n",
    "\n",
    "# ランキング学習のために必要な特徴量とターゲットを設定\n",
    "features = [\n",
    "            'kyori',\n",
    "            'grade_code',\n",
    "            'seibetsu_code',\n",
    "            'moshoku_code',\n",
    "            'barei',\n",
    "            'chokyoshi_code',\n",
    "            'banushi_code',\n",
    "            'kishu_code',\n",
    "            'kishu_minarai_code',\n",
    "            'kyoso_shubetsu_code',\n",
    "            'juryo_shubetsu_code',\n",
    "            'shusso_tosu',\n",
    "            'tenko_code',\n",
    "            'babajotai_code_dirt',\n",
    "            'hutan_wariai',\n",
    "            'zogen_ryou',\n",
    "            'track_code',\n",
    "            'keibajo_code'\n",
    "            ]\n",
    "\n",
    "target = 'kakutei_chakujun'\n",
    "\n",
    "# LightGBM用のデータセットを作成\n",
    "train_dataset = lgb.Dataset(train_data[features], label=train_data[target])\n",
    "\n",
    "def objective(trial):\n",
    "    # Optunaで調整するパラメータを設定\n",
    "    params = {\n",
    "        'objective': 'regression',\n",
    "        'metric': 'rmse',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 2, 256),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 1e-4, 1e-1, log=True),\n",
    "        'feature_fraction': trial.suggest_float('feature_fraction', 0.4, 1.0),\n",
    "    }\n",
    "    \n",
    "    # k=5のFOLDでデータを分割\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    # 各FOLDでの評価値を保存するためのリスト\n",
    "    rmses = []\n",
    "    \n",
    "    # LightGBMモデルを訓練\n",
    "    for train_index, valid_index in kf.split(train_data):\n",
    "        train_fold_data = train_data.iloc[train_index]\n",
    "        valid_fold_data = train_data.iloc[valid_index]\n",
    "        \n",
    "        train_dataset = lgb.Dataset(train_fold_data[features], label=train_fold_data[target])\n",
    "        valid_dataset = lgb.Dataset(valid_fold_data[features], label=valid_fold_data[target])\n",
    "        \n",
    "        model = lgb.train(params, train_dataset, num_boost_round=1000, valid_sets=[valid_dataset], early_stopping_rounds=100, verbose_eval=100)\n",
    "        \n",
    "        # RMSEを計算して保存\n",
    "        y_pred = model.predict(valid_fold_data[features])\n",
    "        rmse = np.sqrt(mean_squared_error(valid_fold_data[target], y_pred))\n",
    "        rmses.append(rmse)\n",
    "    \n",
    "    # 5-FOLDの平均RMSEを返す\n",
    "    return np.mean(rmses)\n",
    "\n",
    "# Optunaでのパラメータ探索を実行\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=10)\n",
    "\n",
    "# 最適なパラメータ\n",
    "best_params = study.best_params\n",
    "best_params['metric'] = 'rmse'  # ここでmetricを追加\n",
    "\n",
    "# KFoldでのモデル訓練\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "models = []\n",
    "\n",
    "for train_index, valid_index in kf.split(train_data):\n",
    "    train_fold_data = train_data.iloc[train_index]\n",
    "    valid_fold_data = train_data.iloc[valid_index]\n",
    "    \n",
    "    train_dataset = lgb.Dataset(train_fold_data[features], label=train_fold_data[target])\n",
    "    valid_dataset = lgb.Dataset(valid_fold_data[features], label=valid_fold_data[target])\n",
    "    \n",
    "    model = lgb.train(best_params, train_dataset, num_boost_round=500, valid_sets=[valid_dataset], early_stopping_rounds=20, verbose_eval=100)  # ここでearly_stopping_roundsを50に変更\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50618bb5-4841-4cb9-b4cb-cc029629358c",
   "metadata": {},
   "source": [
    "### テストデータで予測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "59de8ac9-a8f5-45fc-a650-2f6d47ffc9d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>predicted_rank</th>\n",
       "      <th>kakutei_chakujun</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1635601</th>\n",
       "      <td>2021-222-83-2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1635602</th>\n",
       "      <td>2021-222-83-2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1635603</th>\n",
       "      <td>2021-222-83-2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1635604</th>\n",
       "      <td>2021-222-83-2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1635605</th>\n",
       "      <td>2021-101-45-1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1785604</th>\n",
       "      <td>2021-1231-54-11</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1785605</th>\n",
       "      <td>2021-1231-54-11</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1785606</th>\n",
       "      <td>2021-1231-54-11</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1785607</th>\n",
       "      <td>2021-1231-54-11</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1785608</th>\n",
       "      <td>2021-1231-54-11</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>147974 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   group  predicted_rank  kakutei_chakujun\n",
       "1635601    2021-222-83-2             4.0                 6\n",
       "1635602    2021-222-83-2             1.0                 7\n",
       "1635603    2021-222-83-2            10.0                 1\n",
       "1635604    2021-222-83-2             3.0                 2\n",
       "1635605    2021-101-45-1             6.0                 1\n",
       "...                  ...             ...               ...\n",
       "1785604  2021-1231-54-11            10.0                 3\n",
       "1785605  2021-1231-54-11             4.0                 1\n",
       "1785606  2021-1231-54-11             7.0                 2\n",
       "1785607  2021-1231-54-11             3.0                11\n",
       "1785608  2021-1231-54-11             2.0                 5\n",
       "\n",
       "[147974 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2020年から2022年のテストデータを取得\n",
    "test_data_2020 = merged_df[merged_df['kaisai_nen'] == 2020].copy()\n",
    "test_data_2021 = merged_df[merged_df['kaisai_nen'] == 2021].copy()\n",
    "test_data_2022 = merged_df[merged_df['kaisai_nen'] == 2022].copy()\n",
    "\n",
    "# 2021年と2022年のデータに対して予測を行い、平均を取る\n",
    "test_data_2020.loc[:, 'y_pred'] = sum([model.predict(test_data_2020[features], num_iteration=model.best_iteration) for model in models]) / len(models)\n",
    "test_data_2021.loc[:, 'y_pred'] = sum([model.predict(test_data_2021[features], num_iteration=model.best_iteration) for model in models]) / len(models)\n",
    "test_data_2022.loc[:, 'y_pred'] = sum([model.predict(test_data_2022[features], num_iteration=model.best_iteration) for model in models]) / len(models)\n",
    "\n",
    "# 予測されたランクをグループごとに計算\n",
    "test_data_2020.loc[:, 'predicted_rank'] = test_data_2020.groupby('group')['y_pred'].rank(method='min')\n",
    "test_data_2021.loc[:, 'predicted_rank'] = test_data_2021.groupby('group')['y_pred'].rank(method='min')\n",
    "test_data_2022.loc[:, 'predicted_rank'] = test_data_2022.groupby('group')['y_pred'].rank(method='min')\n",
    "\n",
    "# 結果を表示\n",
    "test_data_2021[['group', 'predicted_rank', 'kakutei_chakujun']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68cb294d-cc15-4ece-8051-7e9a1f1ca38c",
   "metadata": {},
   "source": [
    "## モデル評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b3c7ea0-effe-4b02-a1db-9f38b16e8542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021 RMSE: 360.321%\n",
      "2021 RMSE: 368.128%\n",
      "2022 RMSE: 367.274%\n",
      "Mean RMSE: 365.241%\n"
     ]
    }
   ],
   "source": [
    "# RMSEを計算\n",
    "rmse_2020 = np.sqrt(mean_squared_error(test_data_2020['predicted_rank'], test_data_2020['kakutei_chakujun']))\n",
    "print(f\"2021 RMSE: {rmse_2020:.3%}\")\n",
    "rmse_2021 = np.sqrt(mean_squared_error(test_data_2021['predicted_rank'], test_data_2021['kakutei_chakujun']))\n",
    "print(f\"2021 RMSE: {rmse_2021:.3%}\")\n",
    "rmse_2022 = np.sqrt(mean_squared_error(test_data_2022['predicted_rank'], test_data_2022['kakutei_chakujun']))\n",
    "print(f\"2022 RMSE: {rmse_2022:.3%}\")\n",
    "rmse_mean = np.mean([rmse_2020, rmse_2021, rmse_2022])\n",
    "print(f\"Mean RMSE: {rmse_mean:.3%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e30bd02-d1ac-42c2-a20c-b50cf1b86283",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_ids_2020 = test_data_2020['group'].unique()\n",
    "precisions = []\n",
    "recalls = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "67d558ef-cfb1-42ed-aebf-8a7d6e851def",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_at_5(predictions, actual):\n",
    "    top_5_predictions = predictions.argsort()[-5:][::-1]  # 予測の上位5頭のインデックス\n",
    "    top_3_actual = actual.argsort()[-3:][::-1]  # 実際の上位3頭のインデックス\n",
    "    common_elements = np.intersect1d(top_5_predictions, top_3_actual)  # 共通の要素を抽出\n",
    "    precision = len(common_elements) / 5\n",
    "    return precision\n",
    "\n",
    "def recall_at_5(predictions, actual):\n",
    "    top_5_predictions = predictions.argsort()[-5:][::-1]  # 予測の上位5頭のインデックス\n",
    "    top_3_actual = actual.argsort()[-3:][::-1]  # 実際の上位3頭のインデックス\n",
    "    common_elements = np.intersect1d(top_5_predictions, top_3_actual)  # 共通の要素を抽出\n",
    "    recall = len(common_elements) / 3\n",
    "    return recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "19fcf8c0-d484-4492-9ca0-2e4b65bb7c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_top3_in_top5_predictions(group):\n",
    "    predicted_top5 = group.nsmallest(5, 'y_pred').index.tolist()\n",
    "    actual_top3 = group.nsmallest(3, 'kakutei_chakujun').index.tolist()\n",
    "    return all([horse in predicted_top5 for horse in actual_top3])\n",
    "\n",
    "def calculate_group_profit(group):\n",
    "    if check_top3_in_top5_predictions(group):\n",
    "        payout_value = group['haraimodoshi_sanrenpuku_1b'].iloc[0]\n",
    "        return payout_value - 1000\n",
    "    else:\n",
    "        return -1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7b30d6ff-8e24-4188-9d8f-f569b483b0c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020 Precision@5: 39.063%\n",
      "2020 Recall@5: 65.105%\n"
     ]
    }
   ],
   "source": [
    "for test_data in [test_data_2020, test_data_2021, test_data_2022]:\n",
    "    merged_data = test_data\n",
    "    profits = merged_data.groupby('group').apply(calculate_group_profit).reset_index()\n",
    "    profits.columns = ['group', 'profit']\n",
    "    test_data = pd.merge(test_data, profits, on='group', how='left')\n",
    "\n",
    "for group_id in group_ids_2020:\n",
    "    test_data = test_data_2020[test_data_2020['group'] == group_id]\n",
    "    p = precision_at_5(test_data['predicted_rank'].values, test_data['kakutei_chakujun'].values)\n",
    "    r = recall_at_5(test_data['predicted_rank'].values, test_data['kakutei_chakujun'].values)\n",
    "    precisions.append(p)\n",
    "    recalls.append(r)\n",
    "\n",
    "precision_5_2020 = np.mean(precisions)\n",
    "recall_5_2020 = np.mean(recalls)\n",
    "\n",
    "print(f\"2020 Precision@5: {precision_5_2020:.3%}\")\n",
    "print(f\"2020 Recall@5: {recall_5_2020:.3%}\")\n",
    "\n",
    "group_ids_2021 = test_data_2021['group'].unique()\n",
    "precisions = []\n",
    "recalls = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5c260fed-21fe-4db0-9bbb-e378b2443d33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021 Precision@5: 38.441%\n",
      "2021 Recall@5: 64.069%\n",
      "2022 Precision@5: 38.422%\n",
      "2022 Recall@5: 64.037%\n",
      "Mean Precision@5: 38.642%\n",
      "Mean Recall@5: 64.403%\n",
      "2020 Average Net Profit: 575.074 yen\n",
      "2021 Average Net Profit: 537.796 yen\n",
      "2022 Average Net Profit: 573.642 yen\n",
      "Mean Average Net Profit: 562.170 yen\n"
     ]
    }
   ],
   "source": [
    "for group_id in group_ids_2021:\n",
    "    test_data = test_data_2021[test_data_2021['group'] == group_id]\n",
    "    p = precision_at_5(test_data['predicted_rank'].values, test_data['kakutei_chakujun'].values)\n",
    "    r = recall_at_5(test_data['predicted_rank'].values, test_data['kakutei_chakujun'].values)\n",
    "    precisions.append(p)\n",
    "    recalls.append(r)\n",
    "\n",
    "precision_5_2021 = np.mean(precisions)\n",
    "recall_5_2021 = np.mean(recalls)\n",
    "\n",
    "print(f\"2021 Precision@5: {precision_5_2021:.3%}\")\n",
    "print(f\"2021 Recall@5: {recall_5_2021:.3%}\")\n",
    "\n",
    "\n",
    "roup_ids_2022 = test_data_2022['group'].unique()\n",
    "precisions = []\n",
    "recalls = []\n",
    "\n",
    "for group_id in roup_ids_2022:\n",
    "    test_data = test_data_2022[test_data_2022['group'] == group_id]\n",
    "    p = precision_at_5(test_data['predicted_rank'].values, test_data['kakutei_chakujun'].values)\n",
    "    r = recall_at_5(test_data['predicted_rank'].values, test_data['kakutei_chakujun'].values)\n",
    "    precisions.append(p)\n",
    "    recalls.append(r)\n",
    "\n",
    "precision_5_2022 = np.mean(precisions)\n",
    "recall_5_2022 = np.mean(recalls)\n",
    "\n",
    "print(f\"2022 Precision@5: {precision_5_2022:.3%}\")\n",
    "print(f\"2022 Recall@5: {recall_5_2022:.3%}\")\n",
    "\n",
    "\n",
    "precision_5_mean = np.mean([precision_5_2020, precision_5_2021, precision_5_2022])\n",
    "recall_5_mean = np.mean([recall_5_2020, recall_5_2021, recall_5_2022])\n",
    "\n",
    "print(f\"Mean Precision@5: {precision_5_mean:.3%}\")\n",
    "print(f\"Mean Recall@5: {recall_5_mean:.3%}\")\n",
    "\n",
    "# 各レースで上記の関数を適用\n",
    "results_2020 = test_data_2020.groupby('group').apply(check_top3_in_top5_predictions)\n",
    "results_2021 = test_data_2021.groupby('group').apply(check_top3_in_top5_predictions)\n",
    "results_2022 = test_data_2022.groupby('group').apply(check_top3_in_top5_predictions)\n",
    "\n",
    "# 予測モデルが成功したレースのインデックスを取得する\n",
    "successful_groups_2020 = results_2020[results_2020].index\n",
    "successful_groups_2021 = results_2021[results_2021].index\n",
    "successful_groups_2022 = results_2022[results_2022].index\n",
    "\n",
    "# そのインデックスを使用して、harai_dfから対応する支払倍率を取得する\n",
    "successful_payout_2020 = merged_df[merged_df['group'].isin(successful_groups_2020)]\n",
    "successful_payout_2021 = merged_df[merged_df['group'].isin(successful_groups_2021)]\n",
    "successful_payout_2022 = merged_df[merged_df['group'].isin(successful_groups_2022)]\n",
    "\n",
    "payouts_2020 = successful_payout_2020['haraimodoshi_sanrenpuku_1b']\n",
    "payouts_2021 = successful_payout_2021['haraimodoshi_sanrenpuku_1b']\n",
    "payouts_2022 = successful_payout_2022['haraimodoshi_sanrenpuku_1b']\n",
    "\n",
    "# すべての成功したレースに対して、100円をかけた場合の支払いを計算する\n",
    "total_payout_2020 = (payouts_2020).sum()\n",
    "total_payout_2021 = (payouts_2021).sum()\n",
    "total_payout_2022 = (payouts_2022).sum()\n",
    "\n",
    "# 合計の支払いから、すべてのレースにかけた合計金額を引くことで、純利益を計算する\n",
    "total_investment_2020 = test_data_2020['group'].nunique() * 1000\n",
    "total_investment_2021 = test_data_2021['group'].nunique() * 1000\n",
    "total_investment_2022 = test_data_2021['group'].nunique() * 1000\n",
    "\n",
    "net_profit_2020 = total_payout_2020 - total_investment_2020\n",
    "net_profit_2021 = total_payout_2021 - total_investment_2021\n",
    "net_profit_2022 = total_payout_2022 - total_investment_2022\n",
    "\n",
    "average_net_profit_2020 = net_profit_2020/len(test_data_2020)\n",
    "average_net_profit_2021 = net_profit_2021/len(test_data_2021)\n",
    "average_net_profit_2022 = net_profit_2020/len(test_data_2022)\n",
    "\n",
    "print(f\"2020 Average Net Profit: {average_net_profit_2020:.3f} yen\")\n",
    "print(f\"2021 Average Net Profit: {average_net_profit_2021:.3f} yen\")\n",
    "print(f\"2022 Average Net Profit: {average_net_profit_2022:.3f} yen\")\n",
    "\n",
    "mean_average_net_profit = np.mean([average_net_profit_2020, average_net_profit_2021, average_net_profit_2022])\n",
    "print(f\"Mean Average Net Profit: {mean_average_net_profit:.3f} yen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cba3cc9d-fed6-4870-8be0-6eafd8219f67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# models[0]の特徴量の重要度を取得\n",
    "feature_importance = models[0].feature_importance(importance_type='gain')\n",
    "\n",
    "# 特徴量の名前と重要度をDataFrameに変換\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': features,\n",
    "    'Importance': feature_importance\n",
    "})\n",
    "\n",
    "# 重要度の降順にソート\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# プロット\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.barplot(data=importance_df, x='Importance', y='Feature')\n",
    "plt.title('Feature Importance')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b012e5-3fdb-4152-966e-1b76dd8e46bc",
   "metadata": {},
   "source": [
    "# モデル保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7f56bbe4-89fe-4ca0-8ee4-3c4a6daed162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.056380 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1265\n",
      "[LightGBM] [Info] Number of data points in the train set: 2017402, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 5.554518\n",
      "Model saved to ../app/models/model.pkl\n"
     ]
    }
   ],
   "source": [
    "# 学習\n",
    "full_train_dataset = lgb.Dataset(merged_df[features], label=merged_df[target])\n",
    "full_model = lgb.train(best_params, full_train_dataset, num_boost_round=500, verbose_eval=100)  # ここではvalid_setsやearly_stopping_roundsは使用しない\n",
    "\n",
    "# モデルを保存\n",
    "model_save_path = '../app/models/model.pkl'\n",
    "with open(model_save_path, 'wb') as f:\n",
    "    pickle.dump(full_model, f)\n",
    "\n",
    "print(f\"Model saved to {model_save_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
