{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72ca9841-adc6-4612-b82f-f2f94a32faa7",
   "metadata": {},
   "source": [
    "# config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094f5968-12ce-4237-9072-7428ee19e6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "racecourse = 'morioka'\n",
    "race_id = 202335100905\n",
    "kaisai_nen = '2023'\n",
    "kaisai_tsukihi = '1009'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4391343-55d4-4c48-9774-127a1a610fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "race_bango = '05'\n",
    "keibajo_code = '35'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e4baee-3dad-4d0a-b265-c4a09d8bee24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tenko_code = 4\n",
    "# # 0\t未設定・未整備時の初期値(主に地方競馬・海外国際レースに関するデータ)\n",
    "# # 1\t晴\tFine\n",
    "# # 2\t曇\tCloudy\n",
    "# # 3\t雨\tRainy\n",
    "# # 4\t小雨\tDrizzle\n",
    "# # 5\t雪\tSnow\n",
    "# # 6\t小雪\tLight Snow\n",
    "\n",
    "\n",
    "# babajotai_code_dirt = 3\n",
    "# # 0\t未設定・未整備時の初期値(主に地方競馬・海外国際レースに関するデータ)\n",
    "# # 1\t良\tFirm\tStandard\n",
    "# # 2\t稍重\tGood\tGood\n",
    "# # 3\t重\tYielding\tMuddy\n",
    "# # 4\t不良\tSoft\tSloppy\n",
    "\n",
    "\n",
    "# juryo_shubetsu_code = 0\n",
    "# # 0\t未設定・未整備時の初期値(主に地方競馬・海外国際レースに関するデータ)\n",
    "# # 1\tハンデ\tHANDICAP\t出走馬の実績等を考慮し、ハンデキャッパーが負担重量を決定するレース\n",
    "# # 2\t別定\tSPECIAL WEIGHT\tレースごとに負担重量を決定する基準が設けられているレース\n",
    "# # 3\t馬齢\tWEIGHT FOR AGE\t馬の年齢や性別によって負担重量を決定するレース\n",
    "# # 4\t定量\tSPECIAL WEIGHT\t別定レースであって、馬の年齢や性別によって負担重量を決定するレース\n",
    "\n",
    "# shusso_tosu = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473bbdff-b21e-4259-8663-c324060f9cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update_bataiju = {\n",
    "#     1: 493,\n",
    "#     2: 502,\n",
    "#     3: 479,\n",
    "#     4: 451,\n",
    "#     5: 466,\n",
    "#     6: 594,\n",
    "#     7: 431,\n",
    "#     8: 489,\n",
    "#     9: 508,\n",
    "#     10: 427,\n",
    "#     11: 503,\n",
    "#     # 12: 420,\n",
    "# }\n",
    "\n",
    "# update_zogen_fugo = {\n",
    "#     1: '+',\n",
    "#     2: '+',\n",
    "#     3: '-',\n",
    "#     4: '-',\n",
    "#     5: '-',\n",
    "#     6: '-',\n",
    "#     7: '-',\n",
    "#     8: '+',\n",
    "#     9: '+',\n",
    "#     10: '-',\n",
    "#     11: '-',\n",
    "#     # 12: '+',\n",
    "# }\n",
    "\n",
    "# update_zogen_sa = {\n",
    "#     1: 1,\n",
    "#     2: 1,\n",
    "#     3: 7,\n",
    "#     4: 19,\n",
    "#     5: 2,\n",
    "#     6: 1,\n",
    "#     7: 4,\n",
    "#     8: 7,\n",
    "#     9: 5,\n",
    "#     10: 1,\n",
    "#     11: 7,\n",
    "#     # 12: 5,\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d127aa-802a-4ec0-9fc9-e2671c2dba1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import psycopg2\n",
    "import configparser\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#モデル\n",
    "import lightgbm as lgb\n",
    "\n",
    "#クロスバリデーション\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "#エヴァリュエーション\n",
    "from sklearn.metrics import precision_score, recall_score, mean_squared_error\n",
    "\n",
    "#可視化\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "#保存\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd10e2e5-a22a-4858-a78d-762fcab63076",
   "metadata": {},
   "source": [
    "# scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b2209a-7ff3-4287-ab11-187874892037",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "url = f'https://nar.netkeiba.com/race/shutuba.html?race_id={race_id}'\n",
    "#url = f'https://race.netkeiba.com/race/shutuba.html?race_id={race_id}'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "# race基本情報\n",
    "race_list = [race_id]\n",
    "horse_list_list = []\n",
    "title = soup.find('title').text\n",
    "race_name, date = title.split(' | ')[0], title.split(' | ')[1]\n",
    "try:\n",
    "    extracted_race_name = race_name.split(' ')[0]\n",
    "    race_list.append(extracted_race_name)\n",
    "except:\n",
    "    race_list.append(race_name)\n",
    "match_date = re.search(r'(\\d{4})年(\\d{1,2})月(\\d{1,2})日', date)\n",
    "year, month, day = match_date.groups()\n",
    "match_place_race = re.search(r'(\\w+)(\\d{1,2})R', date)\n",
    "place, race_number = match_place_race.groups()\n",
    "race_list.append(int(year))\n",
    "race_list.append(int(month))\n",
    "race_list.append(int(day))\n",
    "race_list.append(place)\n",
    "race_list.append(int(race_number))\n",
    "\n",
    "try:\n",
    "    # 頭数の情報を含む要素を取得\n",
    "    race_data_02_element = soup.select_one('.RaceData02')\n",
    "    # 頭数のテキストを取得\n",
    "    if race_data_02_element:\n",
    "        race_data_02_text = race_data_02_element.get_text()\n",
    "        # 頭数の情報を取得\n",
    "        horse_count_match = re.search(r'(\\d+)頭', race_data_02_text)\n",
    "        if horse_count_match:\n",
    "            race_list.append(int(horse_count_match.group(1)))\n",
    "except:\n",
    "    race_list.append(None)\n",
    "\n",
    "# ダートまたは芝の情報を取得\n",
    "try:\n",
    "    race_data_element = soup.select_one('.RaceData01')\n",
    "    if race_data_element:\n",
    "        race_data_text = race_data_element.get_text()\n",
    "        ground_match = re.search(r'(ダ|芝)\\d+m', race_data_text)\n",
    "        if ground_match:\n",
    "            ground_type = ground_match.group(1)\n",
    "            race_list.append(ground_type)\n",
    "except:\n",
    "    race_list.append(None)\n",
    "\n",
    "try:\n",
    "    race_data_element = soup.select_one('.RaceData01')\n",
    "    # 天候と馬場状態のテキストを取得\n",
    "    if race_data_element:\n",
    "        race_data_text = race_data_element.get_text()  \n",
    "        # 天候の情報を取得\n",
    "        weather_match = re.search(r'天候:(\\w+)', race_data_text)\n",
    "        if weather_match:\n",
    "            race_list.append(weather_match.group(1))\n",
    "        # 馬場状態の情報を取得\n",
    "        track_condition_match = re.search(r'馬場:(\\w+)', race_data_text)\n",
    "        if track_condition_match:\n",
    "            race_list.append(track_condition_match.group(1))\n",
    "except:\n",
    "    race_list.extend([None, None])\n",
    "\n",
    "#tableの情報を取得\n",
    "horse_tables = soup.findAll(\"table\", class_=\"RaceTable01\")\n",
    "horse_table = horse_tables[0].findAll('tr', class_=\"HorseList\")\n",
    "\n",
    "# 取り消しの馬の数をカウントする変数\n",
    "cancel_count = 0\n",
    "\n",
    "#tableの情報から各情報を抜き出す\n",
    "for i in range(len(horse_table)):\n",
    "    horse_list = [race_id]\n",
    "    result_row = horse_table[i].findAll(\"td\")\n",
    "        \n",
    "    # 馬の名前の整理\n",
    "    horse_list.append(result_row[3].get_text().strip())\n",
    "\n",
    "    # 取り消しのチェック\n",
    "    if \"Cancel\" in horse_table[i].get(\"class\"):\n",
    "        horse_list.append(\"取消\")\n",
    "        cancel_count += 1  # 取り消しの馬の数をカウント\n",
    "    else:\n",
    "        horse_list.append(\"出走\")\n",
    "    \n",
    "    horse_list.append(int(result_row[0].get_text().strip()))  # 枠\n",
    "    horse_list.append(int(result_row[1].get_text().strip()))  # 番号\n",
    "    \n",
    "    # 馬体重の整理\n",
    "    try:\n",
    "        weight_match = re.match(r'(\\d+)\\(([-+]?\\d+)\\)', result_row[8].get_text().strip())\n",
    "        body_weight, body_weight_diff = weight_match.groups()\n",
    "        horse_list.append(float(body_weight))  # 馬体重\n",
    "        horse_list.append(float(body_weight_diff))  # 増減差\n",
    "    except:\n",
    "        horse_list.extend([None, None])\n",
    "\n",
    "    # オッズの整理\n",
    "    odds = result_row[9].get_text().strip().split('\\n')[0]\n",
    "    cleaned_odds = re.sub(r\"[^0-9.]\", \"\", odds)\n",
    "    if cleaned_odds:\n",
    "        horse_list.append(float(cleaned_odds))\n",
    "    else:\n",
    "        horse_list.append(None)\n",
    "    \n",
    "    # 人気の整理\n",
    "    popularity = result_row[10].get_text().strip().split('\\n')[0]\n",
    "    cleaned_popularity = re.sub(r\"[^0-9]\", \"\", popularity)\n",
    "    if cleaned_popularity:\n",
    "        horse_list.append(float(cleaned_popularity))\n",
    "    else:\n",
    "        horse_list.append(None)\n",
    "\n",
    "    horse_list_list.append(horse_list)\n",
    "race_df = pd.DataFrame(columns = ['race_id','race_title','year', 'month', 'day', 'place', 'race_number', 'total', 'type', 'weather', 'condition'])\n",
    "horse_df = pd.DataFrame(columns = ['race_id', 'horse_name', 'mark', 'frame_number','horse_number', 'weight', 'weight_diff', 'odds', 'popular'])\n",
    "\n",
    "for horse_list in horse_list_list:\n",
    "    horse_se = pd.Series( horse_list, index=horse_df.columns)\n",
    "    horse_df = pd.concat([horse_df, horse_se.to_frame().T], ignore_index=True)\n",
    "race_se = pd.Series(race_list, index=race_df.columns )\n",
    "race_df = pd.concat([race_df, race_se.to_frame().T], ignore_index=True)\n",
    "\n",
    "race_df['total'] = race_df['total'] - cancel_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c868252-e229-4905-89a6-aae7b8c2eac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "race_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba5b4e6-e985-4e41-a366-8b2a8f8b2e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "horse_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8526ddd7-de5c-43b0-a160-4c2dd71a0572",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read('../../config.ini')\n",
    "\n",
    "user = config['postgresql']['user']\n",
    "password = config['postgresql']['password']\n",
    "host = config['postgresql']['host']\n",
    "database = config['postgresql']['database']\n",
    "\n",
    "connection_string = f\"postgresql://{user}:{password}@{host}/{database}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a88f1f-5a91-41d9-9811-fbd2b52fb3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PostgreSQLに接続\n",
    "%load_ext sql\n",
    "%sql $connection_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918a5519-0941-42f7-b26d-d4998373892c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT *\n",
    "FROM nvd_se\n",
    "WHERE kaisai_nen = :kaisai_nen AND kaisai_tsukihi = :kaisai_tsukihi AND race_bango = :race_bango AND keibajo_code = :keibajo_code\n",
    "LIMIT 100;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013ab2f3-b0ad-420b-bf0d-77a6e0796e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_uma_race_sql = %sql SELECT * FROM nvd_se WHERE kaisai_nen = :kaisai_nen AND kaisai_tsukihi = :kaisai_tsukihi AND race_bango = :race_bango AND keibajo_code = :keibajo_code;\n",
    "n_race_sql = %sql SELECT * FROM nvd_ra WHERE kaisai_nen = :kaisai_nen AND kaisai_tsukihi = :kaisai_tsukihi AND race_bango = :race_bango AND keibajo_code = :keibajo_code;\n",
    "n_payout_sql = %sql SELECT * FROM nvd_hr WHERE kaisai_nen = :kaisai_nen AND kaisai_tsukihi = :kaisai_tsukihi AND race_bango = :race_bango AND keibajo_code = :keibajo_code;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87cf77ff-c3ef-43e3-bced-80d32d1caab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_uma_race_df = pd.DataFrame(n_uma_race_sql)\n",
    "n_race_df = pd.DataFrame(n_race_sql)\n",
    "n_payout_df = pd.DataFrame(n_payout_sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b045fe62-d671-465e-bb8b-8c1982473d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_uma_race_df.to_pickle('../../datasets/traindata/rawdata/n_uma_race.pkl')\n",
    "n_race_df.to_pickle('../../datasets/traindata/rawdata/n_race.pkl')\n",
    "n_payout_df.to_pickle('../../datasets/traindata/rawdata/n_payout.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79a1db4-b62b-49ef-aca6-32583b614362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_uma_race_df = n_uma_race_df[n_uma_race_df['keibajo_code'] == keibajo_code]\n",
    "# n_uma_race_df = n_uma_race_df[n_uma_race_df['race_bango'] == race_bango]\n",
    "\n",
    "# n_race_df = n_race_df[n_race_df['keibajo_code']== keibajo_code]\n",
    "# n_race_df = n_race_df[n_race_df['race_bango'] == race_bango]\n",
    "\n",
    "# n_uma_race_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2285d37-d75e-43f9-b6c7-13a9e6293199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 新しいグループを作成\n",
    "n_uma_race_df['group'] = n_uma_race_df['kaisai_nen'].astype(int).astype(str) +\"-\"+ n_uma_race_df['kaisai_tsukihi'].astype(int).astype(str) +\"-\"+  n_uma_race_df['keibajo_code'].astype(int).astype(str) +\"-\"+  n_uma_race_df['race_bango'].astype(int).astype(str)\n",
    "n_race_df['group'] = n_race_df['kaisai_nen'].astype(int).astype(str) +\"-\"+ n_race_df['kaisai_tsukihi'].astype(int).astype(str) +\"-\"+  n_race_df['keibajo_code'].astype(int).astype(str) +\"-\"+  n_race_df['race_bango'].astype(int).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69911816-43a3-4549-8da9-2f67de5c944a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_race_df = n_race_df.drop(['kaisai_nen', 'kaisai_tsukihi', 'keibajo_code', 'kaisai_kai', 'kaisai_nichime', 'race_bango'],axis=1)\n",
    "merged_df = pd.merge(n_uma_race_df, n_race_df, on='group', how='left')\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0dec926-4b50-4806-bc9c-ba1bdb7a4448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルを読み込む\n",
    "model_file_path = f'../bestmodels/{racecourse}.pkl'\n",
    "with open(model_file_path, 'rb') as f:\n",
    "    models = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6451c6a1-b91b-4ceb-855c-72d1acaed249",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for horse_num, bataiju in update_bataiju.items():\n",
    "#     merged_df.loc[merged_df['umaban'].astype(int) == horse_num, 'bataiju'] = bataiju\n",
    "\n",
    "# for horse_num, zogen_fugo in update_zogen_fugo.items():\n",
    "#     merged_df.loc[merged_df['umaban'].astype(int) == horse_num, 'zogen_fugo'] = zogen_fugo\n",
    "\n",
    "# for horse_num, zogen_sa in update_zogen_sa.items():\n",
    "#     merged_df.loc[merged_df['umaban'].astype(int) == horse_num, 'zogen_sa'] = zogen_sa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb4f28c-1a79-47c8-8dd6-56948d127380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_df['bataiju']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53740ae3-0cd6-4ad6-8429-92796ad25774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_df['zogen_sa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de40321b-8f9f-4300-babf-c4b8350e3125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_df['zogen_fugo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6da868-026e-42ba-b222-66e16084a888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # マッピング辞書\n",
    "# mapping = {\n",
    "#             '+': 2,\n",
    "#             ' ':1,\n",
    "#             '-': 0  \n",
    "#             }\n",
    "# # 'zogenfugo' エンコード\n",
    "# merged_df['zogen_fugo'] = merged_df['zogen_fugo'].map(mapping)\n",
    "\n",
    "mapping = {\n",
    "    'A': '1',\n",
    "    'B': '2',\n",
    "    'C': '3',\n",
    "    'D': '4',\n",
    "    'E': '5',\n",
    "    'F': '6',\n",
    "    'G': '7',\n",
    "    'H': '8',\n",
    "}\n",
    "merged_df['grade_code'] = merged_df['grade_code'].map(mapping).fillna(0)\n",
    "\n",
    "mapping = {\n",
    "    'A00': '100',\n",
    "    'A01': '101',\n",
    "    'A02': '102',\n",
    "    'A03': '103',\n",
    "    'A04': '104',\n",
    "    'A05': '105',\n",
    "    'A06': '106',\n",
    "    'A07': '107',\n",
    "    'A08': '108',\n",
    "    'A09': '109',\n",
    "    'A10': '110',\n",
    "    'A20': '120',\n",
    "    'A21': '121',\n",
    "    'A22': '122',\n",
    "    'A23': '123',\n",
    "    'A24': '124',\n",
    "    'A25': '125',\n",
    "    'N00': '1400',\n",
    "    'N01': '1401',\n",
    "    'N02': '1402',\n",
    "    'N03': '1403',\n",
    "    'N04': '1404',\n",
    "    'N05': '1405',\n",
    "    'N06': '1406',\n",
    "    'N07': '1407',\n",
    "    'N08': '1408',\n",
    "    'N09': '1409',\n",
    "    'N10': '1410',\n",
    "    'N20': '1420',\n",
    "    'N21': '1421',\n",
    "    'N22': '1422',\n",
    "    'N23': '1423',\n",
    "    'N24': '1424',\n",
    "    'N25': '1425',\n",
    "    'N41': '1441',\n",
    "    'N44': '1444',\n",
    "    'M00': '1300',\n",
    "    'M01': '1301',\n",
    "    'M02': '1302',\n",
    "    'M03': '1303',\n",
    "    'M04': '1304',\n",
    "    'M05': '1305',\n",
    "}\n",
    "merged_df['kyoso_kigo_code'] = merged_df['kyoso_kigo_code'].map(mapping).fillna(0)\n",
    "\n",
    "mapping = {\n",
    "    'A ': '1',\n",
    "    'B ': '2',\n",
    "    'C ': '3',\n",
    "    'D ': '4',\n",
    "    }\n",
    "\n",
    "merged_df['course_kubun'] = merged_df['course_kubun'].map(mapping).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75023bf-88a3-4b16-b6df-668639faa2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['tenko_code'] = np.nan\n",
    "merged_df['babajotai_code_dirt'] = np.nan\n",
    "merged_df['shusso_tosu'] = np.nan\n",
    "merged_df['zogen_ryou'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02813def-9ddb-402b-acba-9c2a7b62dc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {\n",
    "    '晴': '1',\n",
    "    '曇': '2',\n",
    "    '雨': '3',\n",
    "    '小雨': '4',\n",
    "    '雪': '5',\n",
    "    '小雪': '6',\n",
    "    }\n",
    "\n",
    "race_df['tenko_code'] = race_df['weather'].map(mapping)\n",
    "\n",
    "mapping = {\n",
    "    '良': '1',\n",
    "    '稍': '2',\n",
    "    '稍重': '2',\n",
    "    '重': '3',\n",
    "    '不良': '4',\n",
    "    }\n",
    "\n",
    "race_df['babajotai_code_dirt'] = race_df['condition'].map(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25da737a-7c42-491a-b795-21f57077a8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['tenko_code'] = race_df['tenko_code'].iloc[0]\n",
    "merged_df['babajotai_code_dirt'] = race_df['babajotai_code_dirt'].iloc[0]\n",
    "merged_df['shusso_tosu'] = race_df['total'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b3476e-7a31-46b3-948a-4a74d3f31cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['tenko_code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48e3795-d914-4199-9c2d-110e3251db42",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# カラム名を変更\n",
    "horse_df = horse_df.rename(columns={\n",
    "    'horse_number': 'umaban',\n",
    "    'weight': 'bataiju',\n",
    "    'weight_diff': 'zogen_ryou'\n",
    "})\n",
    "\n",
    "horse_df['umaban'] = horse_df['umaban'].astype(int)\n",
    "merged_df['umaban'] = merged_df['umaban'].astype(int)\n",
    "\n",
    "merged_df = merged_df.merge(horse_df[['umaban', 'bataiju']], on='umaban', how='left', suffixes=('', '_new'))\n",
    "merged_df = merged_df.merge(horse_df[['umaban', 'zogen_ryou']], on='umaban', how='left', suffixes=('', '_new'))\n",
    "merged_df['bataiju'] = merged_df['bataiju_new'].combine_first(merged_df['bataiju'])\n",
    "merged_df['zogen_ryou'] = merged_df['zogen_ryou_new'].combine_first(merged_df['zogen_ryou'])\n",
    "merged_df.drop(columns=['bataiju_new', 'zogen_ryou_new'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e011286-3e3e-44a1-b6bd-58185a237bb9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# def combine_sign_and_diff(row):\n",
    "#     if row['zogen_fugo'] == 2:\n",
    "#         return row['zogen_sa']\n",
    "#     elif row['zogen_fugo'] == 0:\n",
    "#         return -row['zogen_sa']\n",
    "#     else:\n",
    "#         return 0\n",
    "\n",
    "# merged_df['zogen_ryou'] = merged_df.apply(combine_sign_and_diff, axis=1)\n",
    "\n",
    "# # scaler = MinMaxScaler()\n",
    "# # merged_df['zogen_ryou'] = scaler.fit_transform(merged_df[['zogen_ryou']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf0e11e-b5b5-40dc-af8c-268713d7107d",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['bataiju']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092aae02-949f-4c0f-891a-075b6b216b4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "merged_df['hutan_wariai'] = merged_df['futan_juryo'].astype(int) / pd.to_numeric(merged_df['bataiju'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8df8cba-1e24-457b-a1e4-7b650d72b6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['hutan_wariai']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a6a3f9-f0a9-4b80-9141-c352c7f066d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['zogen_ryou']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7745ae-749c-40ff-929c-081a09f30ee8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# カラムのデータ型をstrに変換\n",
    "columns_to_convert = [\n",
    "                        'kyori',\n",
    "                        'grade_code',\n",
    "                        'seibetsu_code',\n",
    "                        'moshoku_code',\n",
    "                        'barei',\n",
    "                        'chokyoshi_code',\n",
    "                        'banushi_code',\n",
    "                        'kishu_code',\n",
    "                        'kishu_minarai_code',\n",
    "                        'kyoso_shubetsu_code',\n",
    "                        'juryo_shubetsu_code',\n",
    "                        'shusso_tosu',\n",
    "                        'tenko_code',\n",
    "                        'babajotai_code_dirt',\n",
    "                        'hutan_wariai',\n",
    "                        'zogen_ryou',\n",
    "                        ]\n",
    "\n",
    "for column in columns_to_convert:\n",
    "    # 欠損値を0に変換\n",
    "    merged_df[column].fillna(0, inplace=True)\n",
    "    \n",
    "    # 値がすべて整数であるかどうかを確認\n",
    "    try:\n",
    "        if merged_df[column].astype(float).apply(lambda x: x.is_integer()).all():\n",
    "            merged_df[column] = merged_df[column].astype(int)\n",
    "        else:\n",
    "            merged_df[column] = merged_df[column].astype(float)\n",
    "    except ValueError:\n",
    "        # 文字列などの非数値データが含まれている場合は、float に変換\n",
    "        merged_df[column] = merged_df[column].astype(float)\n",
    "    \n",
    "    print(f\"{column} のデータ型: {merged_df[column].dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50618bb5-4841-4cb9-b4cb-cc029629358c",
   "metadata": {},
   "source": [
    "### ターゲットデータで予測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f0f1be-78e6-4a58-8476-b077d712f025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ランキング学習のために必要な特徴量とターゲットを設定\n",
    "features = [\n",
    "            'kyori',\n",
    "            'grade_code',\n",
    "            'seibetsu_code',\n",
    "            'moshoku_code',\n",
    "            'barei',\n",
    "            'chokyoshi_code',\n",
    "            'banushi_code',\n",
    "            'kishu_code',\n",
    "            'kishu_minarai_code',\n",
    "            'kyoso_shubetsu_code',\n",
    "            'juryo_shubetsu_code',\n",
    "            'shusso_tosu',\n",
    "            'tenko_code',\n",
    "            'babajotai_code_dirt',\n",
    "            'hutan_wariai',\n",
    "            'zogen_ryou',\n",
    "            ]\n",
    "\n",
    "\n",
    "target = 'kakutei_chakujun'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d798ced-0e4b-4199-8d98-060abee5be1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df[features].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a89fd11-aef9-4ddb-959b-a0222294f13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e167de-0cfb-4f94-b8a8-fe22d36d53e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"取消\" の umaban を取得\n",
    "cancelled_umabans = horse_df[horse_df['mark'] == '取消']['umaban']\n",
    "\n",
    "# その umaban を持つ merged_df の行を削除\n",
    "merged_df = merged_df[~merged_df['umaban'].isin(cancelled_umabans)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182f10c4-d526-4043-b9f7-e56983dee3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_df['y_pred'] = sum([model.predict(merged_df[features], num_iteration=model.best_iteration) for model in models]) / len(models)\n",
    "merged_df['y_pred'] = models.predict(merged_df[features], num_iteration=models.best_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97ee078-d1e8-42ea-9d04-2ce27af0da84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 予測されたランクをグループごとに計算\n",
    "merged_df['predicted_rank'] = merged_df.groupby('group')['y_pred'].rank(method='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65eae5d5-1429-4e4b-befe-362d04234c0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# groupとpredicted_rankでソート\n",
    "sorted_df = merged_df.sort_values(by=['group', 'predicted_rank'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90581478-a5cd-402c-b4ad-131380b3ee39",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_df[['predicted_rank', 'bamei', 'umaban', 'zogen_ryou', 'hutan_wariai', 'shusso_tosu', 'juryo_shubetsu_code', 'y_pred']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
